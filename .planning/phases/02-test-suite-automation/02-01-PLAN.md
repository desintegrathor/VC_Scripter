---
phase: 02-test-suite-automation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - vcdecomp/tests/test_validation.py
  - vcdecomp/tests/conftest.py
autonomous: false

must_haves:
  truths:
    - "Developer runs `pytest vcdecomp/tests/test_validation.py` and sees results for all test scripts"
    - "Test suite decompiles each .scr file and compiles the output"
    - "Test suite compares recompiled bytecode to original"
    - "Test failures show detailed error information (compilation errors or bytecode differences)"
    - "Developer can run individual test scripts with pytest -k flag for focused debugging"
  artifacts:
    - path: "vcdecomp/tests/test_validation.py"
      provides: "Parametrized pytest tests for decompilation validation workflow"
      min_lines: 80
      exports: ["test_decompilation_validation"]
    - path: "vcdecomp/tests/conftest.py"
      provides: "Shared fixtures for compiler paths and validation orchestrator"
      min_lines: 20
      exports: ["compiler_paths", "validation_orchestrator"]
  key_links:
    - from: "vcdecomp/tests/test_validation.py"
      to: "ValidationOrchestrator"
      via: "validation_orchestrator fixture"
      pattern: "validation_orchestrator\\.validate"
    - from: "vcdecomp/tests/test_validation.py"
      to: "decompiler_source_tests/"
      via: "TEST_SCRIPTS list with parametrization"
      pattern: "decompiler_source_tests/test[0-9]+/.*\\.scr"
    - from: "test_validation.py"
      to: "structure module"
      via: "format_structured_function_named"
      pattern: "format_structured_function_named"
---

<objective>
Create pytest-based automated validation test suite that validates all test scripts through the complete decompile → compile → compare workflow.

Purpose: Enable iterative improvement workflow with fast feedback loop - developer can run `pytest vcdecomp/tests/test_validation.py` to measure current decompilation quality and identify failures.

Output: Working pytest test suite that validates 3 test scripts from `decompiler_source_tests/`, showing compilation success/failure and bytecode comparison results.
</objective>

<execution_context>
@C:\Users\flori\source\repos\VC_Scripter\.planning\.claude\get-shit-done\workflows\execute-plan.md
@C:\Users\flori\source\repos\VC_Scripter\.planning\.claude\get-shit-done\templates\summary.md
</execution_context>

<context>
@C:\Users\flori\source\repos\VC_Scripter\.planning\PROJECT.md
@C:\Users\flori\source\repos\VC_Scripter\.planning\ROADMAP.md
@C:\Users\flori\source\repos\VC_Scripter\.planning\STATE.md

# Phase-specific context
@C:\Users\flori\source\repos\VC_Scripter\.planning\phases\02-test-suite-automation\02-CONTEXT.md
@C:\Users\flori\source\repos\VC_Scripter\.planning\phases\02-test-suite-automation\02-RESEARCH.md

# Prior phase summaries (foundation for this phase)
@C:\Users\flori\source\repos\VC_Scripter\.planning\phases\01-gui-validation-integration\01-01-SUMMARY.md
@C:\Users\flori\source\repos\VC_Scripter\.planning\phases\01-gui-validation-integration\01-02-SUMMARY.md

# Existing test patterns
@C:\Users\flori\source\repos\VC_Scripter\vcdecomp\tests\test_end_to_end_decompilation.py

# Validation subsystem (mature, production-ready)
@C:\Users\flori\source\repos\VC_Scripter\vcdecomp\validation\validator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create pytest validation test suite with parametrization</name>

  <files>
    vcdecomp/tests/test_validation.py
    vcdecomp/tests/conftest.py
  </files>

  <action>
Create `vcdecomp/tests/conftest.py` with shared fixtures:
- `compiler_paths()` fixture (session scope): Returns dict with compiler_dir and include_dirs paths from `original-resources/compiler`
- `validation_orchestrator(compiler_paths)` fixture (session scope): Creates ValidationOrchestrator with cache_enabled=False (always fresh decompilation per user requirement), timeout=120

Create `vcdecomp/tests/test_validation.py` implementing the complete validation workflow:

**Test corpus discovery:**
```python
TEST_SCRIPTS = [
    pytest.param("test1/tt", Path("decompiler_source_tests/test1/tt.scr"),
                 Path("decompiler_source_tests/test1/tt.c"), id="tt-turntable"),
    pytest.param("test2/tdm", Path("decompiler_source_tests/test2/tdm.scr"),
                 Path("decompiler_source_tests/test2/tdm.c"), id="tdm-deathmatch"),
    pytest.param("test3/LEVEL", Path("decompiler_source_tests/test3/LEVEL.SCR"),
                 Path("decompiler_source_tests/test3/LEVEL.C"), id="level-script"),
]
```

**Test function structure:**
```python
@pytest.mark.parametrize("test_id,scr_path,original_c", TEST_SCRIPTS)
def test_decompilation_validation(test_id, scr_path, original_c, validation_orchestrator, tmp_path):
    """
    Test complete decompile → compile → compare workflow.

    Success criteria:
    1. Decompilation produces valid C code
    2. C code compiles successfully with original compiler
    3. Recompiled bytecode is semantically equivalent to original
    """
```

**Implementation steps in test function:**

1. **Decompile step** - Use existing decompilation pipeline (following test_end_to_end_decompilation.py patterns):
   - Load SCRFile from scr_path
   - Build SSA: `build_ssa_all_blocks(scr)`
   - Get function boundaries from Disassembler
   - Generate includes: `include_block = generate_include_block(scr)`
   - Analyze globals: `resolver = GlobalResolver(ssa_func, aggressive_typing=True, infer_structs=False)`
   - Call `resolver.analyze()` to populate globals
   - Decompile all functions: `format_structured_function_named()` for each function
   - **Assemble complete .c file:** Combine `include_block + "\n\n" + "\n\n".join(function_outputs)` into single string (NO globals declarations - resolver.analyze() is for internal use, globals are referenced inline within functions)
   - Write assembled content to `tmp_path / f"{test_id}_decompiled.c"`

2. **Validate step** - Call ValidationOrchestrator:
   - `result = validation_orchestrator.validate(scr_path, decompiled_path)`

3. **Report step** - Print detailed results with programmatic error categorization:
   - Print separator line and test ID
   - Print full ValidationResult (has __str__ method)
   - **Extract and report compilation error categories programmatically:**
     ```python
     if not result.compilation_succeeded:
         # Group errors by type
         error_types = {}
         for error in result.compilation_result.errors:
             error_type = error.error_type  # e.g., "syntax", "type", "undefined"
             error_types[error_type] = error_types.get(error_type, 0) + 1
         print(f"\nError breakdown: {error_types}")
     ```
   - **Extract and report bytecode difference categories programmatically:**
     ```python
     if result.categorized_differences:
         from vcdecomp.validation.comparator import DifferenceCategory
         category_counts = {}
         for diff in result.categorized_differences:
             cat = diff.category.name  # e.g., SEMANTIC, COSMETIC, OPTIMIZATION
             category_counts[cat] = category_counts.get(cat, 0) + 1
         print(f"\nBytecode difference breakdown: {category_counts}")
     ```

4. **Assert step** - Use ValidationVerdict for categorization:
   - First assert: `result.compilation_succeeded` with detailed error message showing first 3 compilation errors
   - If compilation succeeded, check verdict:
     - ValidationVerdict.PASS: Print "✓ {test_id}: PASS"
     - ValidationVerdict.PARTIAL: Print "⚠ {test_id}: PARTIAL ({semantic_count} semantic differences)" - DO NOT fail test (user wants to see complete picture)
     - Other verdicts: pytest.fail with unexpected verdict message

**Sequential execution:** No pytest-xdist needed - tests run sequentially by default, giving clearer output.

**Artifact preservation:** Use pytest's tmp_path fixture (per-test temp directory) - auto-cleaned after test. If debugging needed, user can run with `--basetemp=.test_artifacts` to preserve artifacts.

**Error handling:** Tests should NOT use fail-fast mode - continue on failure to collect all results. Each parametrized test is independent.

**Import structure:**
- Use absolute imports from vcdecomp.core, vcdecomp.validation
- Import ValidationVerdict from vcdecomp.validation
- Import DifferenceCategory from vcdecomp.validation.comparator for categorization
- Import pytest for parametrization
- Import Path from pathlib for cross-platform paths

**Design note on task scope:** This single task handles both fixtures and test implementation. While this bundles multiple concerns, the scope is small (3 test scripts, 2 files, ~100 lines total), making the combined implementation manageable and atomic. Splitting would create unnecessary coordination overhead for this straightforward test infrastructure.
  </action>

  <verify>
Run the test suite and confirm it executes all 3 test scripts:

```bash
cd C:\Users\flori\source\repos\VC_Scripter
PYTHONPATH=. python -m pytest vcdecomp/tests/test_validation.py -v
```

Expected output:
- 3 test items collected (one per script)
- Each test runs decompilation pipeline
- Each test attempts compilation via ValidationOrchestrator
- Results show PASS/PARTIAL/FAIL verdict for each script
- Detailed output shows compilation errors or bytecode differences
- **Programmatic error categorization** shown: e.g., "Error breakdown: {'syntax': 5, 'type': 3}"
- **Programmatic bytecode difference categorization** shown: e.g., "Bytecode difference breakdown: {'SEMANTIC': 2, 'COSMETIC': 8}"

Confirm test organization:
```bash
PYTHONPATH=. python -m pytest vcdecomp/tests/test_validation.py --collect-only
```

Should show:
- test_validation.py::test_decompilation_validation[tt-turntable]
- test_validation.py::test_decompilation_validation[tdm-deathmatch]
- test_validation.py::test_decompilation_validation[level-script]
  </verify>

  <done>
- `vcdecomp/tests/test_validation.py` exists with parametrized test function
- `vcdecomp/tests/conftest.py` exists with compiler_paths and validation_orchestrator fixtures
- Running `pytest vcdecomp/tests/test_validation.py -v` shows 3 collected test items
- All 3 tests execute (may pass or fail depending on decompilation quality)
- Test output shows detailed validation results for each script
- **Error categories are extracted programmatically** (not just printed in string output)
- **Bytecode difference categories are extracted programmatically** (not just printed in string output)
- Code follows existing patterns from test_end_to_end_decompilation.py and RESEARCH.md examples
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Automated pytest test suite (`test_validation.py`) that validates all 3 test scripts from `decompiler_source_tests/` through complete decompile → compile → compare workflow.

The test suite:
- Discovers 3 test scripts using pytest parametrization
- Decompiles each .scr file using the structure module pipeline
- Compiles decompiled output with original SCMP.exe compiler
- Compares recompiled bytecode to original using ValidationOrchestrator
- Reports detailed results (compilation errors, bytecode differences)
- **Programmatically extracts and reports error categories** (syntax, type, undefined)
- **Programmatically extracts and reports bytecode difference categories** (SEMANTIC, COSMETIC, OPTIMIZATION)
- Runs sequentially to provide clear output
  </what-built>

  <how-to-verify>
**Step 1: Run the complete test suite**

```bash
cd C:\Users\flori\source\repos\VC_Scripter
PYTHONPATH=. python -m pytest vcdecomp/tests/test_validation.py -v -s
```

**Expected behavior:**
- 3 test items collected and executed sequentially
- Each test shows:
  - Decompilation step (loading, SSA, structure analysis)
  - Compilation step (via ValidationOrchestrator)
  - Results (PASS/PARTIAL/FAIL verdict)
- Detailed output for failures (compilation errors or bytecode differences)
- **Programmatic breakdown** of error types (e.g., "Error breakdown: {'syntax': 5, 'type': 3}")
- **Programmatic breakdown** of bytecode categories (e.g., "Bytecode difference breakdown: {'SEMANTIC': 2, 'COSMETIC': 8}")

**Step 2: Examine test results quality**

Look at the decompiled C code, disassembled .asm files, and original .c files to assess "how deep in shit it is":

For each failing test:
1. Check what compilation errors appear (syntax errors, type errors, undefined symbols)
2. Check the programmatic error breakdown to identify the dominant error category
3. Compare decompiled output structure to original .c file
4. Note patterns in failures (expression reconstruction, variable declarations, control flow)

**Step 3: Verify test organization**

```bash
PYTHONPATH=. python -m pytest vcdecomp/tests/test_validation.py --collect-only
```

Confirm:
- 3 test items with readable IDs (tt-turntable, tdm-deathmatch, level-script)
- Each is an independent test that can be run individually

**Step 4: Test individual script targeting**

```bash
PYTHONPATH=. python -m pytest vcdecomp/tests/test_validation.py::test_decompilation_validation[tt-turntable] -v
```

Confirm: Can run individual test scripts for focused debugging.

**Acceptance criteria:**
✓ All 3 test scripts are discovered and executed
✓ Test output shows detailed validation results
✓ Compilation errors are visible and informative
✓ **Error categories are extracted programmatically** (not just in printed string)
✓ **Bytecode differences are categorized programmatically** (SEMANTIC vs COSMETIC vs OPTIMIZATION)
✓ Tests provide clear feedback for iterative improvement workflow
✓ You can assess the current state of decompilation quality
  </how-to-verify>

  <resume-signal>
After reviewing test results, respond with:

**Option A - Approved:** "approved" - test suite provides sufficient quality measurement

**Option B - Issues found:** Describe specific issues:
- Missing information in test output
- Unclear error messages
- Test organization problems
- Additional debug output needed

**Option C - Quality assessment:** Share observations about decompilation quality:
- What % of tests pass/fail?
- What are the main error categories (syntax, types, control flow)?
- Which test scripts are in better/worse shape?
- Any surprises or insights from seeing actual decompilation quality?
  </resume-signal>
</task>

</tasks>

<verification>
**Overall phase verification:**

1. **Test discovery works:**
   ```bash
   PYTHONPATH=. python -m pytest vcdecomp/tests/test_validation.py --collect-only
   ```
   Output shows 3 test items with readable IDs.

2. **Test execution completes:**
   ```bash
   PYTHONPATH=. python -m pytest vcdecomp/tests/test_validation.py -v
   ```
   All 3 tests execute (pass or fail), showing detailed results.

3. **Individual test targeting:**
   ```bash
   PYTHONPATH=. python -m pytest vcdecomp/tests/test_validation.py -k tt-turntable -v
   ```
   Can target individual scripts for debugging.

4. **Integration with existing validation subsystem:**
   - Tests use ValidationOrchestrator.validate() (not reimplementing compilation)
   - Tests use existing decompilation pipeline (SCRFile, SSA, structure module)
   - Results use ValidationResult and ValidationVerdict for categorization

5. **Requirements satisfied:**
   - TEST-01: ✓ Automated test suite runs decompilation on all test cases
   - TEST-02: ✓ Test suite validates each decompiled output compiles
   - TEST-03: ✓ Test suite compares bytecode for semantic equivalence
   - TEST-04: ✓ Test suite categorizes failures by error type (programmatically extracted from ValidationResult)
   - TEST-07: ✓ pytest integration allows running `pytest vcdecomp/tests/test_validation.py`
</verification>

<success_criteria>
**Phase 2 success criteria (what must be TRUE):**

1. ✓ Test suite runs decompilation on all test cases automatically
   - Running pytest discovers and executes 3 test scripts

2. ✓ Test suite validates each decompiled output compiles successfully
   - Each test calls ValidationOrchestrator.validate()
   - Compilation results are captured and reported

3. ✓ Test suite compares bytecode and reports semantic equivalence
   - ValidationResult shows bytecode comparison
   - Differences categorized as semantic/cosmetic/optimization

4. ✓ Test suite categorizes failures by error type
   - Compilation errors parsed and displayed
   - **Error types extracted programmatically** (not just string output)
   - **Bytecode difference categories extracted programmatically** (SEMANTIC/COSMETIC/OPTIMIZATION)
   - ValidationVerdict distinguishes PASS/PARTIAL/FAIL

5. ✓ Developer can run `pytest vcdecomp/tests/test_validation.py` to validate entire suite
   - Command works with standard pytest invocation
   - Output is informative for debugging
</success_criteria>

<output>
After completion, create:

`.planning/phases/02-test-suite-automation/02-01-SUMMARY.md`

Following the standard SUMMARY.md template with:
- Performance metrics (duration, commits)
- Test results analysis (how many pass/fail, main error categories)
- Decompilation quality assessment
- Requirements satisfied (TEST-01, TEST-02, TEST-03, TEST-04, TEST-07)
- Next phase readiness (Phase 3 CI/CD, Phase 4 Error Analysis)
</output>
