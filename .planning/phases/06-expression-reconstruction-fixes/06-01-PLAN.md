---
phase: 06-expression-reconstruction-fixes
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .planning/phases/06-expression-reconstruction-fixes/ERROR_BASELINE.md
autonomous: true

must_haves:
  truths:
    - "Error patterns are identified with frequency counts"
    - "Syntax errors are categorized by type (operators, casts, precedence)"
    - "Top 3-5 highest-frequency error patterns are documented"
    - "Baseline metrics exist for measuring fix effectiveness"
  artifacts:
    - path: ".planning/phases/06-expression-reconstruction-fixes/ERROR_BASELINE.md"
      provides: "Documented error patterns with examples and frequencies"
      min_lines: 50
  key_links:
    - from: "vcdecomp/tests/test_validation.py"
      to: "vcdecomp/validation/error_analyzer.py"
      via: "categorize_compilation_errors function"
      pattern: "categorize_compilation_errors"
---

<objective>
Establish baseline measurement of expression reconstruction errors to guide systematic fixes.

Purpose: Before fixing bugs, we need data-driven understanding of what's broken and how often. This plan runs the validation test suite, categorizes all compilation errors, and identifies the highest-frequency issues to fix first. This prevents ad-hoc fixes and ensures effort targets the most impactful bugs.

Output: ERROR_BASELINE.md documenting error patterns, frequencies, and examples from current decompiler output.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-expression-reconstruction-fixes/06-CONTEXT.md
@.planning/phases/06-expression-reconstruction-fixes/06-RESEARCH.md

# Prior phase outputs (error analysis infrastructure)
@.planning/phases/04-error-analysis-system/04-01-SUMMARY.md
@.planning/phases/04-error-analysis-system/04-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Run validation test suite and collect error data</name>
  <files>None (read-only analysis)</files>
  <action>
Run pytest validation suite to collect current error state:

```bash
cd C:\Users\flori\source\repos\VC_Scripter
PYTHONPATH=. python -m pytest vcdecomp/tests/test_validation.py::test_decompilation_validation -v --basetemp=.test_artifacts_baseline
```

This will:
1. Decompile all 3 test scripts (tt, tdm, LEVEL)
2. Attempt compilation with SCMP.exe
3. Categorize errors using error_analyzer module (Phase 4 output)
4. Print error breakdowns for each test

Capture the full output to analyze error patterns.

Expected outcomes:
- Tests will likely FAIL (decompiler has bugs - that's what we're fixing)
- Compilation errors will be categorized (syntax, semantic, type, include, other)
- Each test will show error counts and first 3 example errors

DO NOT fix any code yet - this is measurement only.
  </action>
  <verify>
```bash
# Check that test artifacts were created
ls .test_artifacts_baseline/test_decompilation_validation*

# Verify decompiled .c files exist
find .test_artifacts_baseline -name "*_decompiled.c"
```
  </verify>
  <done>
- Test suite runs to completion (even if tests fail)
- Output shows error categorization for all 3 test scripts
- Decompiled .c files preserved in .test_artifacts_baseline/
  </done>
</task>

<task type="auto">
  <name>Analyze error patterns and create baseline report</name>
  <files>.planning/phases/06-expression-reconstruction-fixes/ERROR_BASELINE.md</files>
  <action>
Analyze the pytest output from Task 1 and create ERROR_BASELINE.md with:

## Structure

1. **Executive Summary**
   - Total test scripts: 3
   - Compilation success rate: X/3
   - Total compilation errors: N
   - Most common error category: [syntax/semantic/type]

2. **Error Pattern Analysis**
   For each error category, document:
   - Frequency count and percentage
   - Top 3 example errors
   - Affected test scripts
   - Likely root cause in expr.py

3. **Prioritization**
   Rank error patterns by:
   - Frequency (errors per script)
   - Impact (blocks compilation vs cosmetic)
   - Fix complexity (simple vs requires refactoring)

   Create ordered list:
   1. [Pattern A]: XX errors (YY%) - Priority: HIGH/MEDIUM/LOW
   2. [Pattern B]: XX errors (YY%) - Priority: HIGH/MEDIUM/LOW
   ...

4. **Baseline Metrics**
   Document current state for comparison after fixes:
   - tt.scr: [PASS/FAIL] - X syntax errors, Y semantic errors
   - tdm.scr: [PASS/FAIL] - X syntax errors, Y semantic errors
   - LEVEL.scr: [PASS/FAIL] - X syntax errors, Y semantic errors

5. **Fix Targets for Plan 02**
   Identify top 3-5 patterns to fix in next plan based on:
   - High frequency
   - Blocks compilation (vs non-critical)
   - Clearly fixable in expr.py

## Analysis Approach

Read pytest output and for each test:
1. Extract "COMPILATION ERROR ANALYSIS" section
2. Extract error breakdown dict: `{error_type: count}`
3. Extract "First 3 errors" examples
4. Identify patterns (e.g., "missing semicolon", "invalid operator precedence", "type mismatch in cast")

Cross-reference with RESEARCH.md common pitfalls:
- Incorrect operator precedence → expressions like `(a + b) * c` instead of `a + b * c`
- Type confusion (int vs float) → `1` instead of `1.0f`
- Missing type casts → implicit conversions causing errors
- Over/under parenthesization → unreadable or incorrect expressions

Write findings to ERROR_BASELINE.md using Markdown format with code examples.
  </action>
  <verify>
```bash
# Verify baseline report exists and has content
test -f .planning/phases/06-expression-reconstruction-fixes/ERROR_BASELINE.md
wc -l .planning/phases/06-expression-reconstruction-fixes/ERROR_BASELINE.md
# Should be 50+ lines

# Check report contains key sections
grep -q "Executive Summary" .planning/phases/06-expression-reconstruction-fixes/ERROR_BASELINE.md
grep -q "Error Pattern Analysis" .planning/phases/06-expression-reconstruction-fixes/ERROR_BASELINE.md
grep -q "Baseline Metrics" .planning/phases/06-expression-reconstruction-fixes/ERROR_BASELINE.md
```
  </verify>
  <done>
- ERROR_BASELINE.md exists with complete analysis
- Error patterns documented with frequencies and examples
- Top 3-5 fix targets identified for Plan 02
- Baseline metrics recorded for all 3 test scripts
  </done>
</task>

<task type="auto">
  <name>Commit baseline report</name>
  <files>None (git operations)</files>
  <action>
Commit ERROR_BASELINE.md to establish baseline for measuring progress:

```bash
cd C:\Users\flori\source\repos\VC_Scripter
git add .planning/phases/06-expression-reconstruction-fixes/ERROR_BASELINE.md
git commit -m "$(cat <<'EOF'
docs(06-01): establish expression error baseline

- Run validation test suite on 3 test scripts
- Categorize all compilation errors by type
- Document error patterns and frequencies
- Identify top fix targets for systematic debugging

Baseline for measuring Phase 6 fix effectiveness.

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>
EOF
)"
```
  </action>
  <verify>
```bash
# Verify commit created
git log -1 --oneline | grep "docs(06-01)"
```
  </verify>
  <done>
- ERROR_BASELINE.md committed to repository
- Commit message documents baseline purpose
- Ready to proceed to Plan 02 (fix implementation)
  </done>
</task>

</tasks>

<verification>
## Overall Phase Checks

After plan completion:
1. pytest test suite runs successfully (even if tests fail)
2. ERROR_BASELINE.md exists with documented error patterns
3. Top 3-5 fix targets identified and prioritized
4. Baseline metrics recorded for comparison after fixes

## Success Indicators

- Error categorization shows clear patterns (not random failures)
- Syntax errors are majority (expected for expression bugs)
- Fix targets are actionable (specific issues in expr.py, not systemic problems)
</verification>

<success_criteria>
## Measurable Completion

- [ ] Test suite executed with output captured
- [ ] ERROR_BASELINE.md created with 50+ lines of analysis
- [ ] Error patterns categorized with frequency counts
- [ ] Top 3-5 fix targets documented
- [ ] Baseline metrics recorded for all 3 test scripts
- [ ] Report committed to git

## Quality Gates

- Error patterns are specific and actionable (e.g., "missing parentheses in binary expressions" not "syntax errors")
- Frequencies guide prioritization (highest frequency = highest priority)
- Examples include actual error messages and affected code snippets
</success_criteria>

<output>
After completion, create `.planning/phases/06-expression-reconstruction-fixes/06-01-SUMMARY.md`
</output>
